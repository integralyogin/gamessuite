{
"Data Discovery": { "quote": "The process of identifying and cataloging available data assets within an organization. Automated scanning tools can identify previously unknown data repositories." },
"Data Quality Assessment": { "quote": "Evaluating data against quality dimensions such as accuracy, completeness, and consistency. A quality score of 87% may indicate generally reliable data with some issues to address." },
"Statistical Analysis": { "quote": "Applying statistical methods to understand data distributions and patterns. Discovering that your customer age data follows a normal distribution with μ=42 and σ=12 helps target marketing strategies." },
"Metadata Analysis": { "quote": "Examining data about the data, including field definitions, relationships, and lineage. Understanding that 'customer_id' serves as a foreign key across multiple tables enables proper join operations." },
"Data Type Profiling": { "quote": "Identifying and validating the types of data stored in fields. Discovering that a 'date' field contains text values like 'unknown' indicates potential data quality issues." },
"Cardinality Analysis": { "quote": "Measuring the number of distinct values in a field relative to total records. A field with 95% unique values may be a good candidate for a primary key." },
"Pattern Recognition": { "quote": "Identifying recurring formats and structures within data. Finding that phone numbers appear in three different formats points to data standardization needs." },
"Null Analysis": { "quote": "Examining the presence and distribution of null or missing values. A 30% null rate in 'email_address' suggests potential issues with data collection processes." },
"Outlier Detection": { "quote": "Identifying values that significantly deviate from the norm. Discovering transactions that are 5σ above average may indicate fraud or data entry errors." },
"Correlation Analysis": { "quote": "Measuring relationships between different data elements. Finding a strong correlation (r=0.92) between purchase amount and customer lifetime value informs predictive models." },
"Domain Value Analysis": { "quote": "Validating data against expected value ranges or sets. Records where 'state_code' contains values not in the list of valid states indicate data quality issues." },
"Data Redundancy Analysis": { "quote": "Identifying duplicate or redundant information across datasets. Discovering three tables containing similar customer information points to potential data consolidation opportunities." },
"Time Series Analysis": { "quote": "Examining how data changes over time. Recognizing seasonal patterns in sales data helps with inventory planning and forecasting." },
"Dependency Analysis": { "quote": "Identifying functional dependencies between data elements. Understanding that zip code determines city and state can simplify data models." },
"Data Structure Analysis": { "quote": "Examining the organization and relationships within datasets. Recognizing a star schema in data warehouse tables helps optimize query performance." },
"Cross-Field Validation": { "quote": "Checking consistency between related fields. Verifying that 'total_price' equals 'quantity * unit_price' identifies calculation errors." },
"Reference Data Analysis": { "quote": "Comparing data against standard reference sets. Matching product codes against industry standard catalogs identifies non-standard entries." },
"Data Distribution Analysis": { "quote": "Examining how values are distributed across the range of a dataset. Understanding that 80% of transactions come from 20% of customers highlights key business segments." },
"Data Format Analysis": { "quote": "Examining the syntactic structure of data values. Identifying that date fields appear in both MM/DD/YYYY and DD-MM-YYYY formats explains processing inconsistencies." },
"Data Completeness Analysis": { "quote": "Measuring the presence of required data across records. Finding that only 65% of customer records have complete contact information affects marketing campaign reach." },
"Value Frequency Analysis": { "quote": "Measuring how often specific values appear in a dataset. Discovering that 40% of support tickets are categorized as 'Other' suggests poor categorization schema." },
"Custom Validation Rules": { "quote": "Applying business-specific logic to evaluate data quality. Testing that all active loan accounts have payment schedules identifies process gaps." },
"Data Volume Analysis": { "quote": "Measuring the size and growth patterns of datasets. Recognizing that transaction data grows by 50GB monthly informs storage planning." },
"Referential Integrity Analysis": { "quote": "Verifying that relationships between tables are maintained. Finding orphaned records in detail tables indicates potential delete process issues." },
"Semantic Profiling": { "quote": "Analyzing the meaning and context of data elements. Understanding that two systems use different definitions for 'active customer' explains reporting discrepancies." },
"Anomaly Detection": { "quote": "Identifying unusual patterns that don't match expected behavior. Discovering a sudden 200% increase in website traffic from a specific region warrants investigation." },
"Data Lineage Mapping": { "quote": "Tracking the flow and transformation of data across systems. Documenting that customer data passes through three systems before reporting helps troubleshoot quality issues." },
"Constraint Validation": { "quote": "Checking if data adheres to defined business rules. Verifying that all transactions have approval signatures when required ensures compliance." },
"Sensitive Data Identification": { "quote": "Locating personally identifiable information (PII) and other protected data types. Finding credit card numbers in unencrypted fields highlights security risks." },
"Historical Trend Analysis": { "quote": "Examining how data patterns and quality have changed over time. Noting that data completeness has improved by 15% after system upgrades quantifies process improvements." }
}
