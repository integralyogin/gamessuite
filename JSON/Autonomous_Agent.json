{  
  "Agent Architectures": { "quote": "Reactive (Brooks' subsumption) vs. Deliberative (BDI: Belief-Desire-Intention) vs. Hybrid (SOAR/ACT-R)." },  
  "Reinforcement Learning": { "quote": "Q-learning: Q(s,a) ← Q(s,a) + α[r + γmaxQ(s',a') - Q(s,a)] (Sutton & Barto)." },  
  "Multi-Agent Systems": { "quote": "Game Theory: Nash equilibrium → Minimax in competitive environments (e.g., AlphaGo vs. Lee Sedol)." },  
  "Swarm Intelligence": { "quote": "Ant Colony Optimization: Pheromone trails → Emergent pathfinding (ACO, Dorigo)." },  
  "Imitation Learning": { "quote": "Behavioral Cloning: Train policy π(a|s) from expert demonstrations (DAgger algorithm)." },  
  "Self-Driving Agents": { "quote": "Tesla Autopilot: Sensor fusion (LiDAR, cameras) → POMDP planning under uncertainty." },  
  "Ethical Agents": { "quote": "Asilomar Principles: Avoid harm, value alignment (e.g., self-driving trolley problem)." },  
  "Robot Navigation": { "quote": "SLAM: Simultaneous Localization and Mapping via Kalman filters/particle filters." },  
  "Adversarial Agents": { "quote": "Generative Adversarial Networks (GANs): min_G max_D V(D,G) = E[logD(x)] + E[log(1-D(G(z)))]. (Goodfellow 2014)." },  
  "Meta-Learning": { "quote": "MAML: θ' = θ - α∇θL(τ, θ) → Few-shot adaptation to new tasks (Finn et al., 2017)." },  
  "Human-Agent Collaboration": { "quote": "Shared Autonomy: Bayesian inference over human intent (e.g., assistive robotics)." },  
  "Evolutionary Agents": { "quote": "Genetic Algorithms: Fitness-proportionate selection → Mutate/crossover → Evolve policies." },  
  "Decentralized Coordination": { "quote": "Byzantine Fault Tolerance: Consensus via PBFT (Practical Byzantine Fault Tolerance)." },  
  "Explainable Agents": { "quote": "LIME/SHAP: Interpret black-box models → Feature importance scores for trust." },  
  "Agent Communication": { "quote": "ACL (Agent Communication Language): FIPA protocols for cooperative tasks." },  
  "Autonomous Drones": { "quote": "PID control: Thrust ∝ K_p(error) + K_i(∫error) + K_d(derror/dt)." },  
  "Cognitive Architectures": { "quote": "CLARION: Explicit vs. implicit knowledge layers (Sun, 2006)." },  
  "Federated Learning": { "quote": "Train global model ϕ = Σ(w_i * ϕ_i) → Privacy-preserving agent collaboration." },  
  "Agent Simulations": { "quote": "NetLogo: Emergent behavior in predator-prey or traffic flow models." },  
  "AI Safety": { "quote": "Corrigibility: Agents defer to shutdown commands (Soares et al., 2015)." },  
  "Embodied Agents": { "quote": "Sim2Real: Train in Unity/MuJoCo → Deploy to Boston Dynamics Spot." },  
  "Autonomous Economics": { "quote": "AI market makers: Reinforcement learning for dynamic pricing (e.g., Uber surge)." },  
  "Neuromorphic Agents": { "quote": "Spiking Neural Networks (SNNs): Energy-efficient temporal coding (Loihi chip)." },  
  "AGI Pathways": { "quote": "Reward is enough: Hypothesized by Silver et al. (2021) for general intelligence." },  
  "Quantum Agents": { "quote": "Grover's algorithm: O(√N) search for optimal policies in large action spaces." },  
  "Agent Benchmarking": { "quote": "ALE (Arcade Learning Environment): Atari games as RL evaluation tasks." },  
  "Future of Autonomy": { "quote": "AutoGPT: Recursive self-improvement → Autonomous task decomposition." }  
}  
