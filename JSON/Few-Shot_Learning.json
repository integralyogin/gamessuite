{
  "Definition": { "quote": "Few-shot learning enables models to generalize from minimal examples, guided by task-specific prompts. (Brown et al., 2020: 'Language Models are Few-Shot Learners')" },
  "Prompt Templates": { "quote": "Structured prompts frame tasks: 'Translate English to French: \"{input}\" → \"{output}\".'" },
  "Example Selection": { "quote": "Retrieve semantically similar examples: argmax_{x_i} sim(f(x_i), f(query)) (k-NN prompting)." },
  "In-Context Learning": { "quote": "Task demonstration via input-output pairs: LM([example1][example2][test_input]) → prediction." },
  "Meta-Prompting": { "quote": "Guiding the model to self-reflect: 'Think step by step. First, analyze... Then, conclude...'" },
  "Chain-of-Thought": { "quote": "Induce reasoning traces: 'Q: If Alice has 3 apples... A: Let’s think: 3 - 1 = 2, so 2 apples. Answer: 2.' (Wei et al., 2022)" },
  "Instruction Tuning": { "quote": "Fine-tuning on task descriptions: 'Summarize this text: {text} → {summary}.' (FLAN, Wei et al., 2021)" },
  "Dynamic Prompting": { "quote": "Adaptive example retrieval: DPR (Dense Passage Retrieval) + LM inference." },
  "Soft Prompts": { "quote": "Trainable continuous prompts: optimize embeddings e ∈ ℝ^d via ∇ₑL(θ, e). (Lester et al., 2021: 'Prefix-Tuning')" },
  "Calibration": { "quote": "Reduce bias via null prompts: P(y|x) - P(y|'N/A prompt'). (Zhao et al., 2021: 'Contextual Calibration')" },
  "Task-Agnostic Prompts": { "quote": "Universal triggers: 'Let’s solve the problem.' improves robustness across domains." },
  "Role Prompting": { "quote": "Assigning expert roles: 'You are a biologist. Explain...' boosts specificity." },
  "Retrieval-Augmented Few-Shot": { "quote": "External knowledge integration: RAG (Retrieve → Generate). (Lewis et al., 2020)" },
  "Contrastive Prompts": { "quote": "Clarify via counterfactuals: 'Unlike {wrong_answer}, the correct answer is...'" },
  "Multimodal Few-Shot": { "quote": "Fusing text and images: 'Describe this photo: <image> → caption.' (CLIP, Radford et al., 2021)" },
  "Evaluation Metrics": { "quote": "Few-shot accuracy, perplexity, and ROUGE-L for text generation." },
  "Overfitting Risks": { "quote": "Limited examples → high variance: Regularize via dropout or prompt dropout." },
  "Zero-to-Few-Shot": { "quote": "Hybrid approach: Use zero-shot heuristics if examples are unavailable." },
  "Human-in-the-Loop": { "quote": "Iterative refinement: User feedback → update prompts (e.g., AdaTest, Ribeiro et al., 2022)." },
  "Domain Adaptation": { "quote": "Porting prompts across domains: 'Medical: {symptom} → {diagnosis}.'" },
  "Bias Mitigation": { "quote": "Debiasing via balanced examples: Ensure diversity in few-shot samples." },
  "Parameter-Efficiency": { "quote": "Frozen LM + lightweight prompts: 0.1% trainable parameters vs full fine-tuning." },
  "Prompt Ensembles": { "quote": "Aggregate multiple prompts: Majority vote or logit averaging." },
  "Self-Generated Prompts": { "quote": "LM generates its own prompts: 'What prompt would solve this task?'" },
  "Cross-Lingual Transfer": { "quote": "Translate-prompt-translate: Few-shot for low-resource languages." },
  "Scaling Laws": { "quote": "Performance ∝ log(examples): Diminishing returns beyond ~32-64 shots. (Kaplan et al., 2020)" },
  "Tool-Augmented Prompts": { "quote": "Integrate APIs: 'Use calculator: 3^5 = 243. So, the answer is...'" },
  "Ethical Considerations": { "quote": "Risks: Over-reliance on biased examples → amplified stereotypes." },
  "Industrial Applications": { "quote": "Customer support: Few-shot intent classification with 5 examples per class." },
  "Future Directions": { "quote": "Automated prompt generation: Language Models → Prompt Engineers." }
}
