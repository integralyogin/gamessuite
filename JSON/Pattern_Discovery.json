{
  "Clustering": { "quote": "Grouping similar data points: Minimize ∑_{i=1}^k ∑_{x ∈ C_i} ||x - μ_i||² (k-means objective)." },
  "Dimensionality Reduction": { "quote": "Preserve structure in lower dimensions: PCA maximizes variance via eigenvectors of covariance matrix." },
  "Association Rule Learning": { "quote": "Discover co-occurrence patterns: Apriori algorithm (Support(X→Y) = P(X ∪ Y), Confidence = P(Y|X)." },
  "Anomaly Detection": { "quote": "Identify outliers: Isolation Forest partitions data with random splits (path length → anomaly score)." },
  "Topic Modeling": { "quote": "Uncover latent themes: LDA (Latent Dirichlet Allocation) assumes documents = mixture of topics, topics = mixture of words." },
  "Density Estimation": { "quote": "Model underlying distributions: Kernel Density Estimation (KDE): f̂(x) = (1/nh) ∑ K((x - x_i)/h)." },
  "Outlier Detection": { "quote": "Z-score thresholding: |(x - μ)/σ| > 3, or DBSCAN density-based spatial clustering." },
  "Feature Extraction": { "quote": "Autoencoders learn compressed representations: L = ||X - decoder(encoder(X))||²." },
  "Graph Mining": { "quote": "Discover communities: Louvain method maximizes modularity Q = ∑(e_ii - a_i²)." },
  "Time Series Patterns": { "quote": "Autocorrelation for periodicity: ACF(k) = Cov(X_t, X_{t+k})/Var(X_t)." },
  "Biclustering": { "quote": "Simultaneous row-column clustering: δ(X_{ij}, μ_{rc}) minimized (e.g., Cheng-Church algorithm)." },
  "Self-Organizing Maps": { "quote": "Topology-preserving maps: Update weights w_j ← w_j + η(t)h_{ij}(t)(x - w_j)." },
  "Subspace Clustering": { "quote": "Find clusters in subspaces: CLIQUE grid-based method (density thresholds per dimension)." },
  "Co-Occurrence Analysis": { "quote": "Market basket insights: Lift(X→Y) = P(X,Y)/(P(X)P(Y)) > 1 implies association." },
  "Non-negative Matrix Factorization": { "quote": "Parts-based decomposition: X ≈ WH, W ≥ 0, H ≥ 0 (Lee & Seung, 1999)." },
  "Manifold Learning": { "quote": "Unfold nonlinear structures: Isomap preserves geodesic distances via k-NN graphs." },
  "Rule Mining": { "quote": "FP-Growth: Frequent pattern trees avoid candidate generation (Han et al., 2000)." },
  "Pattern Evaluation": { "quote": "Assess significance: Lift, entropy, or silhouette score (s(i) = (b(i) - a(i))/max(a(i), b(i)))." },
  "Concept Drift": { "quote": "Detect shifting patterns: ADWIN (Adaptive Windowing) monitors distribution changes over streams." },
  "Deep Clustering": { "quote": "Joint representation and grouping: DEC (Deep Embedded Clustering) minimizes KL divergence from soft assignments." },
  "Pattern Visualization": { "quote": "t-SNE or UMAP: Preserve local/global structure in 2D/3D embeddings for interpretability." },
  "Pattern Interpretation": { "quote": "SHAP/LIME: Explain clusters via feature importance scores (e.g., ϕ_i for cluster centroids)." },
  "Ethical Patterns": { "quote": "Bias auditing: Ensure discovered patterns don’t encode protected attributes (e.g., ΔDP < ε)." }
}
