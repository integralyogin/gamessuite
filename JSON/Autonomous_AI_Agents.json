{
  "Agent Perception": { "quote": "Sensor fusion: Combine vision (YOLOv8), LiDAR point clouds, and NLP inputs for multimodal understanding." },
  "Decision-Making": { "quote": "Markov Decision Processes (MDPs): Policy π(a|s) → Maximize cumulative reward Σγ^t R(sₜ, aₜ)." },
  "Reinforcement Learning": { "quote": "PPO (Proximal Policy Optimization): θ ← θ + α ∇_θ E[ min(r(θ)Â, clip(r(θ), 1-ε, 1+ε)Â) ]." },
  "World Modeling": { "quote": "Simulate environments: DreamerV3 learns latent dynamics models for planning (Hafner et al., 2023)." },
  "Autonomy Stack": { "quote": "Perception → Planning → Action: ROS2 nodes for SLAM (Simultaneous Localization and Mapping)." },
  "Multi-Agent Systems": { "quote": "Cooperation/competition: Nash equilibria in game theory (e.g., AlphaFold vs. AlphaZero)." },
  "Adaptive Learning": { "quote": "Meta-learning (MAML): ∇_θ L(θ - α∇_θ L(θ, D_train), D_test)." },
  "Memory & Retrieval": { "quote": "Vector databases: FAISS/RAG → Retrieve context for LLM prompts (e.g., GPT-4 + Pinecone)." },
  "Goal-Driven Behavior": { "quote": "Hierarchical RL: High-level goals → Subgoals → Primitive actions (e.g., OpenAI’s GPT-4 + Code Interpreter)." },
  "Ethical Autonomy": { "quote": "Value alignment: Avoid harmful actions via Constitutional AI (Anthropic’s Claude)." },
  "Self-Improvement": { "quote": "Recursive self-enhancement: Agent generates improved training data → Finetunes itself." },
  "Human-AI Interaction": { "quote": "Instructability: 'Chain-of-Thought' prompting for interpretable reasoning (Wei et al., 2022)." },
  "Tool Use": { "quote": "API integration: Agent uses Calculator[3+5], Browser[Search('weather')], or Code[Python]." },
  "Swarm Intelligence": { "quote": "Stigmergy: Decentralized coordination (e.g., ant colony pathfinding → ACO algorithms)." },
  "Safety Mechanisms": { "quote": "Corrigibility: Allow humans to interrupt/override (Soares et al., 2015)." },
  "Embodied Agents": { "quote": "Robotics: Isaac Gym sim → Transfer policies to Boston Dynamics Spot." },
  "Agent Frameworks": { "quote": "AutoGPT, BabyAGI, LangChain: Task decomposition → Execution loops." },
  "Economic Agents": { "quote": "DeFi bots: Arbitrage strategies via Uniswap API and MEV (Maximal Extractable Value)." },
  "Sim2Real Transfer": { "quote": "Domain randomization: Train in varied simulations → Robust real-world deployment." },
  "Explainability": { "quote": "Saliency maps (CV) or attention heatmaps (Transformers) → Debug agent decisions." },
  "Lifelong Learning": { "quote": "Avoid catastrophic forgetting: Elastic Weight Consolidation (Kirkpatrick et al., 2017)." },
  "Agent Societies": { "quote": "Emergent norms: Axelrod’s *Evolution of Cooperation* (Tit-for-Tat strategies)." },
  "Energy Efficiency": { "quote": "TinyML: Quantize models → Run on edge devices (Jetson Nano, Raspberry Pi)." },
  "Regulatory Compliance": { "quote": "GDPR/CCPA: Anonymize data, audit trails for agent decisions." },
  "Adversarial Robustness": { "quote": "Foolbox attacks: Test agent resilience to perturbed inputs (ε < 0.1)." },
  "Self-Awareness": { "quote": "Introspective models: Monitor internal states (e.g., 'Am I uncertain?' → Request human help)." },
  "Agent Evolution": { "quote": "Genetic algorithms: Mutate/crossover policies → Select for fitness (NEAT framework)." },
  "Quantum Agents": { "quote": "Q-learning on quantum annealers: D-Wave → Solve combinatorial optimization." },
  "Future of Autonomy": { "quote": "Artificial General Intelligence (AGI): Recursive self-improvement → Singularity (Bostrom)." }
}
