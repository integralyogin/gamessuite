{

  "Rule-Based Systems": { "quote": "IF-THEN logic: Expert systems (e.g., MYCIN) with static decision trees. No learning." },
  "Supervised Learning Basics": { "quote": "Labeled data → Linear Regression: ŷ = β₀ + β₁x₁ + ... + βₙxₙ. Minimize MSE." },
  "Unsupervised Learning": { "quote": "Clustering: k-means → Minimize ΣΣ||x - μₖ||². Dimensionality reduction via PCA." },
  "Reinforcement Learning (RL)": { "quote": "Q-learning: Q(s,a) ← Q(s,a) + α[r + γmaxQ(s',a') - Q(s,a)]. Policy gradients." },
  "Neural Networks": { "quote": "Perceptrons → MLPs: σ(w·x + b). Backpropagation: ∂L/∂w via chain rule." },
  "Convolutional Networks (CNN)": { "quote": "Feature extraction: Conv2D(kernel_size=3) → MaxPooling → ReLU. ImageNet accuracy ↑." },
  "Recurrent Networks (RNN)": { "quote": "Sequences: hₜ = tanh(Wₕₕhₜ₋₁ + Wₓₕxₜ). LSTM/GRU for long-term memory." },
  "Deep Learning": { "quote": "ResNet-50: Skip connections → Train deeper nets. BatchNorm stabilizes gradients." },
  "Generative Models (GANs)": { "quote": "Minimax: min_G max_D V(D,G) = E[logD(x)] + E[log(1-D(G(z)))]. (Goodfellow 2014)." },
  "Transformers": { "quote": "Attention(Q,K,V) = softmax(QKᵀ/√d)V. BERT/GPT pre-training (Vaswani et al. 2017)." },
  "Transfer Learning": { "quote": "Fine-tuning: Freeze base layers (e.g., ResNet) → Train head on custom dataset." },
  "Federated Learning": { "quote": "Decentralized training: ΔW = Avg(ΔW₁, ΔW₂, ...) → Preserve privacy (GDPR)." },
  "AutoML": { "quote": "Hyperparameter optimization: Bayesian search → NAS (Neural Architecture Search)." },
  "Explainable AI (XAI)": { "quote": "SHAP values: ϕᵢ = Σ_{S⊆N{i}} [|S|!(|N|−|S|−1)!/|N|!] (f(S∪{i}) − f(S))." },
  "Reinforcement Learning (Advanced)": { "quote": "PPO, TRPO: Policy updates with trust regions. AlphaGo’s MCTS + value networks." },
  "Multi-Agent Systems": { "quote": "Nash equilibria: argmax_aᵢ Uᵢ(aᵢ, a₋ᵢ). Emergent cooperation/competition." },
  "Meta-Learning": { "quote": "Learning to learn: θ' = θ - α∇θL(θ, D_{support}) → Test on D_{query}." },
  "AI Safety": { "quote": "Corrigibility: Ensure agents don’t resist shutdown (Soares et al., 2015)." },
  "Neuromorphic Computing": { "quote": "Spiking neural nets: ΔV_membrane = I(t) → Emulate biological neurons." },
  "Quantum Machine Learning": { "quote": "Qubit embeddings: |ψ⟩ = α|0⟩ + β|1⟩. Grover’s algorithm for O(√N) search." },
  "Artificial General Intelligence (AGI)": { "quote": "Turing Test++: Transfer learning across domains (e.g., human-like common sense)." },
  "Ethical AI Systems": { "quote": "Bias audits: Disparate impact ratio < 0.8 (EEOC guidelines). Fairness through awareness." },
  "Swarm Intelligence": { "quote": "Ant colony optimization: Δpheromone ∝ 1/path_length. Decentralized stigmergy." },
  "Autonomous AI Agents": { "quote": "LLM + Tools: GPT-4 → API calls (e.g., book_flight(), send_email())." },
  "AI-Human Collaboration": { "quote": "Cooperative inverse reinforcement learning (CIRL): Infer human preferences." },
  "Self-Improving AI": { "quote": "Recursive self-enhancement: Seed AI → Modify own code (Yudkowsky, 2008)." },
  "Embodied AI": { "quote": "Sim2Real: Train in Unity → Deploy on Boston Dynamics Spot. ROS integration." },
  "AI in Science": { "quote": "AlphaFold: Evoformer → 3D protein structures (RMSD < 1Å accuracy)." },
  "Future AI Frontiers": { "quote": "Consciousness? Integrated information theory (Φ > 0) vs. computationalism." },
  "Foundational Concepts": { "quote": "Artificial Intelligence is the science and engineering of making intelligent machines. (John McCarthy)" },
  "Symbolic AI": { "quote": "Manipulating symbols and rules: IF condition THEN action (Expert Systems)." },
  "Machine Learning Basics": { "quote": "Learning from data: y ≈ f(x;θ), where θ minimizes loss." },
  "Supervised Learning": { "quote": "Labeled data trains models: ŷ = argmax P(y|x;θ) (e.g., SVM, Decision Trees)." },
  "Unsupervised Learning": { "quote": "Discovering patterns without labels: Clustering via k-means or PCA." },
  "Reinforcement Learning": { "quote": "Agent-environment interaction: Q(s,a) ← Q(s,a) + α[r + γmaxQ(s',a') - Q(s,a)]." },
  "Neural Networks": { "quote": "Layered perceptrons: σ(w·x + b) for activation (e.g., ReLU)." },
  "Deep Learning": { "quote": "Hierarchical feature learning: ∇θL(θ) via backpropagation." },
  "Convolutional Networks": { "quote": "Image processing kernels: Conv2D(filters, kernel_size) → Feature Maps." },
  "Recurrent Networks": { "quote": "Sequential data modeling: h_t = tanh(W_hh h_{t-1} + W_xh x_t)." },
  "Transformers": { "quote": "Attention is all you need: QK^T/√d → Softmax → V (Vaswani et al., 2017)." },
  "Natural Language Processing": { "quote": "Tokenize, embed, predict: 'BERT' → Bidirectional Encoder Representations." },
  "Computer Vision": { "quote": "Edge detection → Object recognition: YOLO (You Only Look Once)." },
  "Generative Models": { "quote": "Creating synthetic data: GANs (minmax V(D,G) = E[logD(x)] + E[log(1-D(G(z))])." },
  "Transfer Learning": { "quote": "Reusing pre-trained models: Fine-tuning ResNet on custom datasets." },
  "Ethical AI": { "quote": "Fairness: Ensuring algorithmic bias mitigation (Δ < ε in disparate impact)." },
  "Explainable AI": { "quote": "Interpretability: SHAP values or LIME for model transparency." },
  "AI in Robotics": { "quote": "Actuation + Perception → SLAM (Simultaneous Localization and Mapping)." },
  "Bayesian Networks": { "quote": "Probabilistic graphs: P(X) = ∏P(X_i | Parents(X_i))." },
  "Optimization in AI": { "quote": "Gradient Descent: θ ← θ - η∇θJ(θ)." },
  "AutoML": { "quote": "Automating pipelines: Neural Architecture Search (NAS)." },
  "AI Hardware": { "quote": "TPUs/GPUs accelerate matrix multiplications: FLOPS ↑ → Training time ↓." },
  "AI Safety": { "quote": "Alignment problem: Ensuring AI goals match human values (Russell & Norvig)." },
  "Quantum AI": { "quote": "Qubits for optimization: Grover's algorithm → O(√N) search." },
  "AI in Healthcare": { "quote": "Predictive diagnostics: CNN-based tumor segmentation in MRI scans." },
  "AI for Games": { "quote": "AlphaGo: Monte Carlo Tree Search (MCTS) + Policy-Value Networks." },
  "Swarm Intelligence": { "quote": "Decentralized systems: Ant Colony Optimization (ACO)." },
  "Cognitive Architectures": { "quote": "Modeling human reasoning: ACT-R or SOAR." },
  "AI Philosophy": { "quote": "The Turing Test: Can machines think? (Alan Turing, 1950)." },
  "AI Futures": { "quote": "Singularity: Recursive self-improvement → Superintelligence (Kurzweil)." }
}
